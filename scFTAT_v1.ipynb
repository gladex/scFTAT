{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing of training data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from scFTAT import Transformer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Activation, SpatialDropout1D, Convolution1D, GlobalMaxPooling1D\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "feature = []  \n",
    "expression = pd.read_csv('../finaldata/mouse_kidney/train_data.csv')\n",
    "file = open('../finaldata/mouse_kidney/train_data.csv')\n",
    "lines = file.readlines() \n",
    "line_0 = lines[0].strip('\\n').split(',') \n",
    "\n",
    "for i in range(1,len(line_0)):\n",
    "    tem = list(expression[line_0[i]])    \n",
    "    feature.append(list(tem))\n",
    "    file.close()\n",
    "\n",
    "feature_train = list(feature)\n",
    "label = []\n",
    "file = open('../finaldata/mouse_kidney/train_labels.csv')\n",
    "lable_lines = file.readlines()\n",
    "lable_line_0 = lable_lines[0].strip('\\n').split(',')\n",
    "file.close()\n",
    "\n",
    "for i in range(1,len(lable_line_0)):\n",
    "    label.append(int(lable_line_0[i]))\n",
    "\n",
    "y_train=[]\n",
    "for i in label:\n",
    "    tem =[]\n",
    "    for j in range(0,17):\n",
    "        tem.append(0)\n",
    "    tem[i-1]=1\n",
    "    y_train.append(tem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing of prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = []  \n",
    "testexpression = pd.read_csv('../finaldata/mouse_kidney/test_data.csv')\n",
    "file = open('../finaldata/mouse_kidney/test_data.csv') \n",
    "lines = file.readlines() \n",
    "line_0 = lines[0].strip('\\n').split(',') \n",
    "for i in range(1,len(line_0)):\n",
    "    tem = list(testexpression[line_0[i]])\n",
    "    feature.append(tem)\n",
    "file.close()\n",
    "feature_test = list(feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "dropout = 0.2\n",
    "epoch = 150\n",
    "params_dict = {'kernel_initializer': 'glorot_uniform','kernel_regularizer': l2(0.01),}\n",
    "num_layers = 4\n",
    "model_size = 40\n",
    "num_heads = 5\n",
    "dff_size = 128\n",
    "maxlen = 16\n",
    "vocab_size = 121"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and prediction, and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.conv1d), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv1d/kernel:0' shape=(15, 122, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv1d/bias:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "0\n",
      "117/117 [==============================] - 26s 136ms/step - loss: 2.6883 - accuracy: 0.2057\n",
      "1\n",
      "Epoch 2/2\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 2.0608 - accuracy: 0.4193\n",
      "2\n",
      "Epoch 3/3\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.8282 - accuracy: 0.8243\n",
      "3\n",
      "Epoch 4/4\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.6528 - accuracy: 0.8729\n",
      "4\n",
      "Epoch 5/5\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.5908 - accuracy: 0.8846\n",
      "5\n",
      "Epoch 6/6\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.5673 - accuracy: 0.8870\n",
      "6\n",
      "Epoch 7/7\n",
      "117/117 [==============================] - 16s 135ms/step - loss: 0.5434 - accuracy: 0.8934\n",
      "7\n",
      "Epoch 8/8\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.5094 - accuracy: 0.9014\n",
      "8\n",
      "Epoch 9/9\n",
      "117/117 [==============================] - 16s 134ms/step - loss: 0.5088 - accuracy: 0.9049\n",
      "9\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.4908 - accuracy: 0.8993\n",
      "10\n",
      "Epoch 11/11\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.4663 - accuracy: 0.9065\n",
      "11\n",
      "Epoch 12/12\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.4643 - accuracy: 0.9033\n",
      "12\n",
      "Epoch 13/13\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.4480 - accuracy: 0.9038\n",
      "13\n",
      "Epoch 14/14\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.4328 - accuracy: 0.9087\n",
      "14\n",
      "Epoch 15/15\n",
      "117/117 [==============================] - 16s 133ms/step - loss: 0.4223 - accuracy: 0.9129\n",
      "15\n",
      "Epoch 16/16\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.4177 - accuracy: 0.9121\n",
      "16\n",
      "Epoch 17/17\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.4067 - accuracy: 0.9129\n",
      "17\n",
      "Epoch 18/18\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.3886 - accuracy: 0.9191\n",
      "18\n",
      "Epoch 19/19\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.3805 - accuracy: 0.9164\n",
      "19\n",
      "Epoch 20/20\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.3720 - accuracy: 0.9145\n",
      "20\n",
      "Epoch 21/21\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.3655 - accuracy: 0.9201\n",
      "21\n",
      "Epoch 22/22\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.3649 - accuracy: 0.9169\n",
      "22\n",
      "Epoch 23/23\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.3403 - accuracy: 0.9249\n",
      "23\n",
      "Epoch 24/24\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.3427 - accuracy: 0.9233\n",
      "24\n",
      "Epoch 25/25\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.3447 - accuracy: 0.9215\n",
      "25\n",
      "Epoch 26/26\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.3340 - accuracy: 0.9231\n",
      "26\n",
      "Epoch 27/27\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.3382 - accuracy: 0.9239\n",
      "27\n",
      "Epoch 28/28\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.3182 - accuracy: 0.9199\n",
      "28\n",
      "Epoch 29/29\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.3254 - accuracy: 0.9263\n",
      "29\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 16s 133ms/step - loss: 0.3093 - accuracy: 0.9233\n",
      "30\n",
      "Epoch 31/31\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.3056 - accuracy: 0.9249\n",
      "31\n",
      "Epoch 32/32\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.3031 - accuracy: 0.9252\n",
      "32\n",
      "Epoch 33/33\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.3081 - accuracy: 0.9252\n",
      "33\n",
      "Epoch 34/34\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.3076 - accuracy: 0.9228\n",
      "34\n",
      "Epoch 35/35\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.2917 - accuracy: 0.9298\n",
      "35\n",
      "Epoch 36/36\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.2938 - accuracy: 0.9260\n",
      "36\n",
      "Epoch 37/37\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.2831 - accuracy: 0.9327\n",
      "37\n",
      "Epoch 38/38\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.2792 - accuracy: 0.9287\n",
      "38\n",
      "Epoch 39/39\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.2784 - accuracy: 0.9290\n",
      "39\n",
      "Epoch 40/40\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.2745 - accuracy: 0.9284\n",
      "40\n",
      "Epoch 41/41\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.2671 - accuracy: 0.9348\n",
      "41\n",
      "Epoch 42/42\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.2594 - accuracy: 0.9324\n",
      "42\n",
      "Epoch 43/43\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.2571 - accuracy: 0.9340\n",
      "43\n",
      "Epoch 44/44\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.2665 - accuracy: 0.9298\n",
      "44\n",
      "Epoch 45/45\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.2502 - accuracy: 0.9340\n",
      "45\n",
      "Epoch 46/46\n",
      "117/117 [==============================] - 16s 133ms/step - loss: 0.2543 - accuracy: 0.9322\n",
      "46\n",
      "Epoch 47/47\n",
      "117/117 [==============================] - 16s 135ms/step - loss: 0.2531 - accuracy: 0.9338\n",
      "47\n",
      "Epoch 48/48\n",
      "117/117 [==============================] - 17s 145ms/step - loss: 0.2448 - accuracy: 0.9383\n",
      "48\n",
      "Epoch 49/49\n",
      "117/117 [==============================] - 16s 140ms/step - loss: 0.2509 - accuracy: 0.9364\n",
      "49\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 17s 142ms/step - loss: 0.2274 - accuracy: 0.9410\n",
      "50\n",
      "Epoch 51/51\n",
      "117/117 [==============================] - 16s 139ms/step - loss: 0.2560 - accuracy: 0.9351\n",
      "51\n",
      "Epoch 52/52\n",
      "117/117 [==============================] - 17s 143ms/step - loss: 0.2301 - accuracy: 0.9420\n",
      "52\n",
      "Epoch 53/53\n",
      "117/117 [==============================] - 16s 139ms/step - loss: 0.2365 - accuracy: 0.9378\n",
      "53\n",
      "Epoch 54/54\n",
      "117/117 [==============================] - 17s 141ms/step - loss: 0.2309 - accuracy: 0.9372\n",
      "54\n",
      "Epoch 55/55\n",
      "117/117 [==============================] - 16s 141ms/step - loss: 0.2318 - accuracy: 0.9431\n",
      "55\n",
      "Epoch 56/56\n",
      "117/117 [==============================] - 16s 140ms/step - loss: 0.2283 - accuracy: 0.9394\n",
      "56\n",
      "Epoch 57/57\n",
      "117/117 [==============================] - 16s 134ms/step - loss: 0.2136 - accuracy: 0.9431\n",
      "57\n",
      "Epoch 58/58\n",
      "117/117 [==============================] - 17s 146ms/step - loss: 0.2136 - accuracy: 0.9412\n",
      "58\n",
      "Epoch 59/59\n",
      "117/117 [==============================] - 17s 144ms/step - loss: 0.2153 - accuracy: 0.9458\n",
      "59\n",
      "Epoch 60/60\n",
      "117/117 [==============================] - 17s 145ms/step - loss: 0.2174 - accuracy: 0.9434\n",
      "60\n",
      "Epoch 61/61\n",
      "117/117 [==============================] - 17s 147ms/step - loss: 0.2102 - accuracy: 0.9447\n",
      "61\n",
      "Epoch 62/62\n",
      "117/117 [==============================] - 16s 138ms/step - loss: 0.2186 - accuracy: 0.9426\n",
      "62\n",
      "Epoch 63/63\n",
      "117/117 [==============================] - 16s 137ms/step - loss: 0.2055 - accuracy: 0.9487\n",
      "63\n",
      "Epoch 64/64\n",
      "117/117 [==============================] - 16s 140ms/step - loss: 0.1985 - accuracy: 0.9479\n",
      "64\n",
      "Epoch 65/65\n",
      "117/117 [==============================] - 16s 140ms/step - loss: 0.1906 - accuracy: 0.9463\n",
      "65\n",
      "Epoch 66/66\n",
      "117/117 [==============================] - 16s 137ms/step - loss: 0.2024 - accuracy: 0.9460\n",
      "66\n",
      "Epoch 67/67\n",
      "117/117 [==============================] - 16s 136ms/step - loss: 0.1953 - accuracy: 0.9476\n",
      "67\n",
      "Epoch 68/68\n",
      "117/117 [==============================] - 16s 135ms/step - loss: 0.1879 - accuracy: 0.9490\n",
      "68\n",
      "Epoch 69/69\n",
      "117/117 [==============================] - 16s 137ms/step - loss: 0.1953 - accuracy: 0.9471\n",
      "69\n",
      "Epoch 70/70\n",
      "117/117 [==============================] - 18s 151ms/step - loss: 0.1881 - accuracy: 0.9463\n",
      "70\n",
      "Epoch 71/71\n",
      "117/117 [==============================] - 16s 140ms/step - loss: 0.1869 - accuracy: 0.9517\n",
      "71\n",
      "Epoch 72/72\n",
      "117/117 [==============================] - 17s 146ms/step - loss: 0.1832 - accuracy: 0.9487\n",
      "72\n",
      "Epoch 73/73\n",
      "117/117 [==============================] - 16s 136ms/step - loss: 0.1826 - accuracy: 0.9495\n",
      "73\n",
      "Epoch 74/74\n",
      "117/117 [==============================] - 16s 137ms/step - loss: 0.1722 - accuracy: 0.9541\n",
      "74\n",
      "Epoch 75/75\n",
      "117/117 [==============================] - 17s 143ms/step - loss: 0.1861 - accuracy: 0.9527\n",
      "75\n",
      "Epoch 76/76\n",
      "117/117 [==============================] - 16s 138ms/step - loss: 0.1748 - accuracy: 0.9562\n",
      "76\n",
      "Epoch 77/77\n",
      "117/117 [==============================] - 16s 137ms/step - loss: 0.1726 - accuracy: 0.9506\n",
      "77\n",
      "Epoch 78/78\n",
      "117/117 [==============================] - 16s 138ms/step - loss: 0.1790 - accuracy: 0.9565\n",
      "78\n",
      "Epoch 79/79\n",
      "117/117 [==============================] - 16s 133ms/step - loss: 0.1607 - accuracy: 0.9578\n",
      "79\n",
      "Epoch 80/80\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.1675 - accuracy: 0.9543\n",
      "80\n",
      "Epoch 81/81\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1572 - accuracy: 0.9578\n",
      "81\n",
      "Epoch 82/82\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1504 - accuracy: 0.9626\n",
      "82\n",
      "Epoch 83/83\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1531 - accuracy: 0.9581\n",
      "83\n",
      "Epoch 84/84\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.1478 - accuracy: 0.9647\n",
      "84\n",
      "Epoch 85/85\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1386 - accuracy: 0.9658\n",
      "85\n",
      "Epoch 86/86\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.1471 - accuracy: 0.9634\n",
      "86\n",
      "Epoch 87/87\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1628 - accuracy: 0.9583\n",
      "87\n",
      "Epoch 88/88\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.1434 - accuracy: 0.9658\n",
      "88\n",
      "Epoch 89/89\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1498 - accuracy: 0.9597\n",
      "89\n",
      "Epoch 90/90\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1395 - accuracy: 0.9655\n",
      "90\n",
      "Epoch 91/91\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1340 - accuracy: 0.9661\n",
      "91\n",
      "Epoch 92/92\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1443 - accuracy: 0.9615\n",
      "92\n",
      "Epoch 93/93\n",
      "117/117 [==============================] - 16s 138ms/step - loss: 0.1467 - accuracy: 0.9639\n",
      "93\n",
      "Epoch 94/94\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.1325 - accuracy: 0.9677\n",
      "94\n",
      "Epoch 95/95\n",
      "117/117 [==============================] - 16s 133ms/step - loss: 0.1272 - accuracy: 0.9690\n",
      "95\n",
      "Epoch 96/96\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1333 - accuracy: 0.9647\n",
      "96\n",
      "Epoch 97/97\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1276 - accuracy: 0.9688\n",
      "97\n",
      "Epoch 98/98\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.1302 - accuracy: 0.9677\n",
      "98\n",
      "Epoch 99/99\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1108 - accuracy: 0.9741\n",
      "99\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1400 - accuracy: 0.9623\n",
      "100\n",
      "Epoch 101/101\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1255 - accuracy: 0.9696\n",
      "101\n",
      "Epoch 102/102\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1302 - accuracy: 0.9647\n",
      "102\n",
      "Epoch 103/103\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1290 - accuracy: 0.9688\n",
      "103\n",
      "Epoch 104/104\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1136 - accuracy: 0.9730\n",
      "104\n",
      "Epoch 105/105\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1157 - accuracy: 0.9722\n",
      "105\n",
      "Epoch 106/106\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1230 - accuracy: 0.9701\n",
      "106\n",
      "Epoch 107/107\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.1157 - accuracy: 0.9712\n",
      "107\n",
      "Epoch 108/108\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.1102 - accuracy: 0.9728\n",
      "108\n",
      "Epoch 109/109\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1159 - accuracy: 0.9688\n",
      "109\n",
      "Epoch 110/110\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.1189 - accuracy: 0.9736\n",
      "110\n",
      "Epoch 111/111\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1182 - accuracy: 0.9706\n",
      "111\n",
      "Epoch 112/112\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1126 - accuracy: 0.9704\n",
      "112\n",
      "Epoch 113/113\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1091 - accuracy: 0.9752\n",
      "113\n",
      "Epoch 114/114\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.1134 - accuracy: 0.9744\n",
      "114\n",
      "Epoch 115/115\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1004 - accuracy: 0.9754\n",
      "115\n",
      "Epoch 116/116\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1100 - accuracy: 0.9741\n",
      "116\n",
      "Epoch 117/117\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.1090 - accuracy: 0.9746\n",
      "117\n",
      "Epoch 118/118\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.1104 - accuracy: 0.9725\n",
      "118\n",
      "Epoch 119/119\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1123 - accuracy: 0.9736\n",
      "119\n",
      "Epoch 120/120\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.0939 - accuracy: 0.9773\n",
      "120\n",
      "Epoch 121/121\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0997 - accuracy: 0.9770\n",
      "121\n",
      "Epoch 122/122\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 0.1131 - accuracy: 0.9720\n",
      "122\n",
      "Epoch 123/123\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.0976 - accuracy: 0.9768\n",
      "123\n",
      "Epoch 124/124\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0973 - accuracy: 0.9781\n",
      "124\n",
      "Epoch 125/125\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0964 - accuracy: 0.9773\n",
      "125\n",
      "Epoch 126/126\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0937 - accuracy: 0.9808\n",
      "126\n",
      "Epoch 127/127\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.0972 - accuracy: 0.9786\n",
      "127\n",
      "Epoch 128/128\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0927 - accuracy: 0.9802\n",
      "128\n",
      "Epoch 129/129\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0955 - accuracy: 0.9786\n",
      "129\n",
      "Epoch 130/130\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0978 - accuracy: 0.9786\n",
      "130\n",
      "Epoch 131/131\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0929 - accuracy: 0.9794\n",
      "131\n",
      "Epoch 132/132\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.1030 - accuracy: 0.9754\n",
      "132\n",
      "Epoch 133/133\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0959 - accuracy: 0.9762\n",
      "133\n",
      "Epoch 134/134\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.1013 - accuracy: 0.9752\n",
      "134\n",
      "Epoch 135/135\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.1077 - accuracy: 0.9722\n",
      "135\n",
      "Epoch 136/136\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0909 - accuracy: 0.9821\n",
      "136\n",
      "Epoch 137/137\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0953 - accuracy: 0.9773\n",
      "137\n",
      "Epoch 138/138\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0879 - accuracy: 0.9808\n",
      "138\n",
      "Epoch 139/139\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0852 - accuracy: 0.9813\n",
      "139\n",
      "Epoch 140/140\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0922 - accuracy: 0.9778\n",
      "140\n",
      "Epoch 141/141\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0980 - accuracy: 0.9784\n",
      "141\n",
      "Epoch 142/142\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.0955 - accuracy: 0.9789\n",
      "142\n",
      "Epoch 143/143\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.0776 - accuracy: 0.9848\n",
      "143\n",
      "Epoch 144/144\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0869 - accuracy: 0.9786\n",
      "144\n",
      "Epoch 145/145\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0901 - accuracy: 0.9789\n",
      "145\n",
      "Epoch 146/146\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.0845 - accuracy: 0.9821\n",
      "146\n",
      "Epoch 147/147\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0971 - accuracy: 0.9760\n",
      "147\n",
      "Epoch 148/148\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.0740 - accuracy: 0.9866\n",
      "148\n",
      "Epoch 149/149\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.1074 - accuracy: 0.9746\n",
      "149\n",
      "Epoch 150/150\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.0713 - accuracy: 0.9858\n",
      "[[9.9999964e-01 6.3898233e-09 4.7496770e-11 ... 7.2841505e-10\n",
      "  1.5785113e-10 1.5624096e-12]\n",
      " [9.9998128e-01 2.5663053e-11 2.4494884e-13 ... 2.8225092e-12\n",
      "  1.5857321e-12 6.2538394e-14]\n",
      " [1.2675464e-09 8.8606362e-14 1.3420580e-09 ... 8.9428777e-11\n",
      "  9.9832774e-11 1.7957641e-11]\n",
      " ...\n",
      " [1.5863753e-09 1.7098148e-14 1.0077820e-14 ... 1.8925646e-13\n",
      "  4.7506771e-14 1.7812381e-15]\n",
      " [1.8908281e-03 4.1629632e-05 9.8388520e-11 ... 1.2911497e-08\n",
      "  2.8219205e-09 1.6139024e-11]\n",
      " [9.9999964e-01 2.4016450e-07 2.0040712e-11 ... 2.8647115e-10\n",
      "  1.1095564e-10 2.0970211e-12]]\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = keras.layers.Input(shape=(maxlen,))\n",
    "transformer = Transformer(num_layers=num_layers, model_size=model_size, num_heads=num_heads, dff_size=dff_size,\n",
    "                          vocab_size=vocab_size+1, maxlen=maxlen)\n",
    "final_output = transformer(enc_inputs)\n",
    "final_output = SpatialDropout1D(0.2)(final_output)\n",
    "final_output = Convolution1D(filters=64,kernel_size=15, padding='same', kernel_initializer='glorot_normal',\n",
    "                             kernel_regularizer=l2(0.001))(final_output)\n",
    "final_output = Activation('relu')(final_output)\n",
    "final_output = GlobalMaxPooling1D()(final_output)\n",
    "final_output = Dense(17,'softmax',**params_dict)(final_output)\n",
    "\n",
    "model = Model(inputs=enc_inputs,outputs=final_output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "feature_train = [list(i) for i in feature_train]\n",
    "feature_test = [list(i) for i in feature_test]\n",
    "for i in range(epoch):\n",
    "    print(i)\n",
    "    model.fit(feature_train,y_train,verbose=1,epochs=i+1,initial_epoch=i,batch_size=32,shuffle=True)\n",
    "\n",
    "\n",
    "a = model.predict(x=feature_test,batch_size=32)\n",
    "print(a)\n",
    "with open('../modelsave/mkidney_epoch200.txt','w',newline='') as f:\n",
    "    for i in range(len(a)):\n",
    "        f.write(str(i))\n",
    "        f.write(',')\n",
    "        for j in range(len(a[i])):\n",
    "            f.write(str(a[i][j]))\n",
    "            f.write(',')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the predictions, calculating its prediction metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9040948275862069\n",
      "f1: 0.919012520564608\n",
      "precision: 0.9386245533501208\n",
      "recall: 0.9045070117007556\n",
      "mcc: 0.8924284844266591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,matthews_corrcoef\n",
    "\n",
    "probability = open('../modelsave/mkidney_epoch200.txt')\n",
    "lines = probability.readlines()\n",
    "a = []\n",
    "for i in lines:\n",
    "    temp = i.strip('\\n')\n",
    "    temp_list = temp.split(',')\n",
    "    t = []\n",
    "    for j in range(1,len(temp_list)-1):\n",
    "        t.append(float(temp_list[j]))\n",
    "    a.append(t)\n",
    "\n",
    "labela = []\n",
    "for i in a:\n",
    "    labela.append(i.index(max(i))+1)\n",
    "probability.close()\n",
    "\n",
    "labelb = open('../finaldata/mouse_kidney/test_labels.csv')\n",
    "linesb = labelb.readlines()\n",
    "a = linesb[0].strip('\\n').split(',')\n",
    "b= []\n",
    "for i in range(1,len(a)):\n",
    "    b.append(int(a[i]))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(b)):\n",
    "    if (b[i]==labela[i]):\n",
    "        count +=1\n",
    "print('accuracy:',count/len(b))\n",
    "f1 = f1_score(y_true=b,y_pred=labela,average='macro')\n",
    "precision = precision_score(y_true=b,y_pred=labela,average='macro')\n",
    "recall = recall_score(y_true=b,y_pred=labela,average='macro')\n",
    "mcc = matthews_corrcoef(y_true=b,y_pred=labela,sample_weight=None)\n",
    "print('f1:',f1)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('mcc:',mcc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
